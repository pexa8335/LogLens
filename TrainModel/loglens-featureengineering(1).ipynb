{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11988594,"sourceType":"datasetVersion","datasetId":7540497}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/parseddata/processed_log_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T08:49:07.864060Z","iopub.execute_input":"2025-05-29T08:49:07.864321Z","iopub.status.idle":"2025-05-29T08:50:54.990389Z","shell.execute_reply.started":"2025-05-29T08:49:07.864302Z","shell.execute_reply":"2025-05-29T08:50:54.989318Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df['url'].head().to_dict()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T08:50:54.991782Z","iopub.execute_input":"2025-05-29T08:50:54.992086Z","iopub.status.idle":"2025-05-29T08:50:55.004964Z","shell.execute_reply.started":"2025-05-29T08:50:54.992064Z","shell.execute_reply":"2025-05-29T08:50:55.003812Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{0: '/filter/27|13%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C%DA%A9%D8%B3%D9%84,27|%DA%A9%D9%85%D8%AA%D8%B1%20%D8%A7%D8%B2%205%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C%DA%A9%D8%B3%D9%84,p53',\n 1: '/image/60844/productModel/200x200',\n 2: '/image/61474/productModel/200x200',\n 3: '/image/14925/productModel/100x100',\n 4: '/product/31893/62100/%D8%B3%D8%B4%D9%88%D8%A7%D8%B1-%D8%AE%D8%A7%D9%86%DA%AF%DB%8C-%D9%BE%D8%B1%D9%86%D8%B3%D9%84%DB%8C-%D9%85%D8%AF%D9%84-PR257AT'}"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport re # Thư viện regex\nfrom urllib.parse import urlparse, parse_qs # << QUAN TRỌNG cho urlparse và parse_qs\nfrom scipy.stats import entropy # Cho url_entropy ở Section 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T08:50:55.006055Z","iopub.execute_input":"2025-05-29T08:50:55.006328Z","iopub.status.idle":"2025-05-29T08:50:55.572688Z","shell.execute_reply.started":"2025-05-29T08:50:55.006308Z","shell.execute_reply":"2025-05-29T08:50:55.571806Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Feature extracted from URL","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom urllib.parse import urlparse, parse_qs\nfrom scipy.stats import entropy \n\n# 1. url length\ndf['url_len'] = df['url'].astype(str).apply(len)\n\n# 2. Độ sâu của đường dẫn (số lượng dấu '/' trong path)\n# urlparse(url_string).path sẽ lấy phần path của URL\n# astype(str) để xử lý các giá trị NaN nếu có, chúng sẽ trở thành chuỗi 'nan'\ndf['url_path_depth'] = df['url'].astype(str).apply(lambda x: urlparse(x).path.count('/'))\n\n# 3. Số lượng tham số query\n# urlparse(url_string).query sẽ lấy phần query string\n# parse_qs(...) sẽ parse query string thành dictionary\n# astype(str) để xử lý NaN\ndf['url_query_count'] = df['url'].astype(str).apply(lambda x: len(parse_qs(urlparse(x).query)))\n\n# 4. Entropy của URL (đo độ ngẫu nhiên/phức tạp của chuỗi URL)\n# Cần xử lý trường hợp chuỗi rỗng hoặc rất ngắn có thể gây lỗi hoặc kết quả không có ý nghĩa cho entropy\ndef calculate_entropy(text_string):\n    # Đảm bảo text_string là một chuỗi\n    text = str(text_string) \n    if not text or len(text) < 2: # Entropy không có ý nghĩa với chuỗi quá ngắn hoặc rỗng\n        return 0.0\n    \n    # Tính tần suất xuất hiện của mỗi ký tự\n    prob = [float(text.count(c)) / len(text) for c in dict.fromkeys(list(text))]\n    \n    # Sử dụng scipy.stats.entropy\n    return entropy(prob, base=2) # base=2 để tính entropy theo bit\n\ndf['url_entropy'] = df['url'].astype(str).apply(calculate_entropy)\n\nprint(\"\\n--- Features từ URL (Section 1) đã được tạo ---\")\n# Hiển thị một vài dòng với các feature mới và cột url gốc để đối chiếu\n# Lấy các cột có thể không tồn tại bằng df.get, nếu không sẽ gây lỗi nếu cột chưa có\ncolumns_to_show = ['url', 'url_len', 'url_path_depth', 'url_query_count', 'url_entropy']\nexisting_columns_to_show = [col for col in columns_to_show if col in df.columns]\nif existing_columns_to_show:\n     print(df[existing_columns_to_show].head())\nelse:\n    print(\"Không có cột nào để hiển thị, có thể có lỗi ở bước tạo feature.\")\n\n# Kiểm tra các giá trị NaN trong các cột mới tạo (nếu có)\nnew_feature_cols_s1 = ['url_len', 'url_path_depth', 'url_query_count', 'url_entropy']\nfor col in new_feature_cols_s1:\n    if col in df.columns: # Kiểm tra xem cột đã được tạo chưa\n        print(f\"Số giá trị NaN trong cột '{col}': {df[col].isnull().sum()}\")\n    else:\n        print(f\"Cột '{col}' chưa được tạo.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T08:50:55.573739Z","iopub.execute_input":"2025-05-29T08:50:55.574172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Feature extraction from URL\nsql_injection_pattern = r\"(union\\s*select|select\\s*.*\\s*from|insert\\s*into|delete\\s*from|drop\\s*table|xp_cmdshell|exec\\s*\\(|'select|--|#)\"\nxss_pattern = r\"(<script>|javascript:|onerror\\s*=|<img\\s*src\\s*=\\s*x onerror)\"\npath_traversal_pattern = r\"(\\.\\./|\\.\\.\\\\|%2e%2e%2f|%2e%2e%5c)\"\n# LFI/RFI pattern cần cẩn thận hơn, vì nó có thể khớp với các URL bình thường nếu áp dụng rộng rãi\n# Có lẽ nên tìm các scheme này khi chúng xuất hiện ở những vị trí không mong muốn, ví dụ, giá trị của một tham số.\n# Nếu cột 'url' của bạn không có query string dạng key=value, việc tìm LFI/RFI trong query sẽ không có tác dụng.\n# Chúng ta có thể tìm các mẫu này trực tiếp trong path, nhưng cần cẩn thận với false positives.\nlfi_rfi_path_pattern = r\"(file:\\/\\/|php:\\/\\/input|php:\\/\\/filter)\" \n\ndf['url_has_sqli'] = df['url'].astype(str).apply(lambda x: 1 if re.search(sql_injection_pattern, x, re.IGNORECASE) else 0)\ndf['url_has_xss'] = df['url'].astype(str).apply(lambda x: 1 if re.search(xss_pattern, x, re.IGNORECASE) else 0)\ndf['url_has_path_traversal'] = df['url'].astype(str).apply(lambda x: 1 if re.search(path_traversal_pattern, x) else 0)\n\n# Nếu df['url'] không có query string dạng ?key=value, feature sau sẽ không có nhiều ý nghĩa.\n# Nếu bạn muốn tìm LFI/RFI trong path, bạn có thể làm:\ndf['url_path_has_lfi_rfi_pattern'] = df['url'].astype(str).apply(lambda x: 1 if re.search(lfi_rfi_path_pattern, urlparse(x).path, re.IGNORECASE) else 0)\n\n\ndef get_file_extension(url_path_string): # Đổi tên biến để rõ ràng hơn\n    # Giả sử url_path_string là phần path, có thể có query string hoặc không\n    path_component = urlparse(url_path_string).path\n    if '.' in path_component:\n        filename = path_component.split('/')[-1] # Lấy phần cuối sau dấu /\n        if '.' in filename: # Đảm bảo có dấu chấm trong tên file thực sự\n             return filename.split('.')[-1].lower()\n    return ''\n\ndf['url_file_extension'] = df['url'].astype(str).apply(get_file_extension)\n\ncommon_script_extensions = ['php', 'asp', 'aspx', 'jsp', 'sh', 'bash', 'py', 'exe', 'dll']\ndf['url_is_script_ext'] = df['url_file_extension'].apply(lambda x: 1 if x in common_script_extensions else 0)\n\nprint(\"\\n--- Features từ URL - Mẫu đáng ngờ và Phần mở rộng (Đã sửa) ---\")\nprint(df[['url', 'url_has_sqli', 'url_has_xss', 'url_has_path_traversal', 'url_path_has_lfi_rfi_pattern', 'url_file_extension', 'url_is_script_ext']].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test với các URL có phần mở rộng\ntest_urls_with_ext = ['/path/to/file.php', '/another/script.asp?id=1', '/static/image.Jpg', '/no_extension_here/', '/archive.tar.gz']\nfor test_url in test_urls_with_ext:\n    ext = get_file_extension(test_url) # Giả sử hàm get_file_extension đã được định nghĩa\n    is_script = 1 if ext in common_script_extensions else 0 # Giả sử common_script_extensions đã được định nghĩa\n    print(f\"URL: {test_url}, Extension: '{ext}', IsScript: {is_script}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nPhân phối các phần mở rộng file (Top 20):\")\nprint(df['url_file_extension'].value_counts().nlargest(20))\nprint(f\"\\nSố dòng có url_is_script_ext = 1: {df['url_is_script_ext'].sum()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install user-agents ua-parser pyyaml","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature extracted from user agent","metadata":{}},{"cell_type":"code","source":"from user_agents import parse\n\n# Parse User-Agent string\n# .astype(str) để xử lý NaN, chúng sẽ được parse như một chuỗi 'nan'\n# và thư viện user-agents sẽ trả về một UserAgent object mặc định (generic) cho các chuỗi không hợp lệ.\ndf['ua_parsed'] = df['user_agent'].astype(str).apply(parse)\n\n# 1. Trình duyệt (Browser Family)\ndf['ua_browser_family'] = df['ua_parsed'].apply(lambda ua: ua.browser.family)\n\n# 2. Phiên bản trình duyệt (Major Version)\ndf['ua_browser_version_major'] = df['ua_parsed'].apply(lambda ua: ua.browser.version[0] if ua.browser.version else None)\n\n# 3. Hệ điều hành (OS Family)\ndf['ua_os_family'] = df['ua_parsed'].apply(lambda ua: ua.os.family)\n\n# 4. Phiên bản hệ điều hành (Major Version)\ndf['ua_os_version_major'] = df['ua_parsed'].apply(lambda ua: ua.os.version[0] if ua.os.version else None)\n\n# 5. Thiết bị (Device Family/Brand)\ndf['ua_device_family'] = df['ua_parsed'].apply(lambda ua: ua.device.family)\ndf['ua_device_brand'] = df['ua_parsed'].apply(lambda ua: ua.device.brand)\n\n# 6. Có phải là Bot không?\ndf['ua_is_bot'] = df['ua_parsed'].apply(lambda ua: 1 if ua.is_bot else 0)\n\n# 7. Có phải là thiết bị di động không?\ndf['ua_is_mobile'] = df['ua_parsed'].apply(lambda ua: 1 if ua.is_mobile else 0)\n\n# 8. Có phải là máy tính bảng không?\ndf['ua_is_tablet'] = df['ua_parsed'].apply(lambda ua: 1 if ua.is_tablet else 0)\n\n# 9. Có phải là PC không?\ndf['ua_is_pc'] = df['ua_parsed'].apply(lambda ua: 1 if ua.is_pc else 0)\n\n# 10. Có phải là thiết bị cảm ứng không? (Thường trùng với mobile/tablet)\ndf['ua_is_touch_capable'] = df['ua_parsed'].apply(lambda ua: 1 if ua.is_touch_capable else 0)\n\n# 11. Độ dài chuỗi User-Agent gốc\ndf['ua_length'] = df['user_agent'].astype(str).apply(len)\n\n# 12. Entropy của chuỗi User-Agent gốc (sử dụng lại hàm calculate_entropy từ Section 1)\n# def calculate_entropy(text_string): ... (Đảm bảo hàm này đã được định nghĩa)\ndf['ua_entropy'] = df['user_agent'].astype(str).apply(calculate_entropy)\n\n\n# Hiển thị một vài dòng với các feature mới\ncols_to_show_ua = [\n    'user_agent', 'ua_browser_family', 'ua_os_family', 'ua_device_brand', \n    'ua_is_bot', 'ua_is_mobile', 'ua_is_pc', 'ua_length', 'ua_entropy'\n]\n# Lọc ra các cột thực sự tồn tại trong df để tránh lỗi nếu có cột nào đó không được tạo\nexisting_cols_ua = [col for col in cols_to_show_ua if col in df.columns]\nif existing_cols_ua:\n    print(\"\\n--- Features từ User-Agent ---\")\n    print(df[existing_cols_ua].head())\n\n# Xóa cột ua_parsed trung gian nếu muốn (nó chứa object, tốn bộ nhớ)\ndf.drop('ua_parsed', axis=1, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature extraction from status code","metadata":{}},{"cell_type":"code","source":"# --- Giả sử df đã có cột 'status' (int64) và 'size' (int64) ---\n\n# 1. Status code có phải là lỗi Client không (4xx)?\ndf['status_is_client_error'] = df['status'].apply(lambda x: 1 if 400 <= x < 500 else 0)\n\n# 2. Status code có phải là lỗi Server không (5xx)?\ndf['status_is_server_error'] = df['status'].apply(lambda x: 1 if 500 <= x < 600 else 0)\n\n# 3. Status code có phải là lỗi nói chung không (4xx hoặc 5xx)?\ndf['status_is_error'] = ((df['status_is_client_error'] == 1) | (df['status_is_server_error'] == 1)).astype(int)\n\n# 4. Status code có phải là thành công không (2xx)?\ndf['status_is_success'] = df['status'].apply(lambda x: 1 if 200 <= x < 300 else 0)\n\n# 5. Status code có phải là chuyển hướng không (3xx)?\ndf['status_is_redirect'] = df['status'].apply(lambda x: 1 if 300 <= x < 400 else 0)\n\n# 6. Response size có bằng 0 không?\ndf['size_is_zero'] = df['size'].apply(lambda x: 1 if x == 0 else 0)\n\n# (Chúng ta đã có 'size' trực tiếp, có thể dùng nó cho mô hình.\n#  Nếu muốn, có thể tạo thêm các bin cho size, vd: size_small, size_medium, size_large\n#  nhưng việc này phụ thuộc vào phân phối của size trong dữ liệu của bạn)\n\ncols_to_show_status_size = [\n    'status', 'size', 'status_is_client_error', 'status_is_server_error',\n    'status_is_success', 'status_is_redirect', 'size_is_zero'\n]\nexisting_cols_ss = [col for col in cols_to_show_status_size if col in df.columns]\nif existing_cols_ss:\n    print(\"\\n--- Features từ Status Code và Size ---\")\n    print(df[existing_cols_ss].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature extraction from referrer","metadata":{}},{"cell_type":"code","source":"# --- Giả sử df đã có cột 'referrer' (object/string) ---\n# và hàm calculate_entropy đã được định nghĩa\n\n# 1. Độ dài Referrer\n# .astype(str) để xử lý NaN, chúng sẽ trở thành chuỗi 'nan'\ndf['referrer_len'] = df['referrer'].astype(str).apply(len)\n\n# 2. Entropy của Referrer\ndf['referrer_entropy'] = df['referrer'].astype(str).apply(calculate_entropy)\n\n# 3. Referrer có rỗng không (thường được biểu thị bằng '-' hoặc chuỗi rỗng)?\ndf['referrer_is_empty'] = df['referrer'].apply(lambda x: 1 if x == '-' or pd.isna(x) or str(x).strip() == '' else 0)\n\n# 4. Trích xuất domain của referrer (nếu có)\ndef get_referrer_domain(referrer_string):\n    ref_str = str(referrer_string)\n    if pd.isna(referrer_string) or ref_str == '-' or not ref_str.startswith('http'):\n        return 'none' # Hoặc 'empty', 'internal' tùy theo cách bạn muốn xử lý\n    try:\n        # urlparse cần URL đầy đủ, nếu referrer chỉ là path thì sẽ không có netloc\n        parsed_ref = urlparse(ref_str)\n        if parsed_ref.netloc:\n            return parsed_ref.netloc.lower()\n        else: # Có thể là một path nội bộ hoặc một URL không chuẩn\n            return 'unknown_format_but_not_empty'\n    except Exception: # Bắt các lỗi parsing URL không mong muốn\n        return 'parse_error'\n\ndf['referrer_domain'] = df['referrer'].apply(get_referrer_domain)\n\n# 5. Referrer có phải là từ một domain khác với domain của trang web bạn đang phân tích không?\n#    (Cần biết domain của trang web bạn, ví dụ: 'yourwebsite.com')\n#    Nếu không biết, có thể so sánh với các domain phổ biến nhất trong dữ liệu referrer.\n#    Ở đây, chúng ta sẽ tạo một feature đơn giản là \"referrer không phải là none/empty\"\ndf['referrer_is_external_or_valid'] = df['referrer_domain'].apply(lambda x: 0 if x in ['none', 'parse_error', 'unknown_format_but_not_empty'] else 1)\n\n\ncols_to_show_ref = [\n    'referrer', 'referrer_len', 'referrer_entropy', \n    'referrer_is_empty', 'referrer_domain', 'referrer_is_external_or_valid'\n]\nexisting_cols_ref = [col for col in cols_to_show_ref if col in df.columns]\nif existing_cols_ref:\n    print(\"\\n--- Features từ Referrer ---\")\n    print(df[existing_cols_ref].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Behavioral/Frequency features","metadata":{}},{"cell_type":"code","source":"# --- Giả sử df đã có cột 'ip', 'event_id_method_url', 'status_is_error', 'url_query_count' ---\n\n# 1. Số lượng request từ một IP\ndf['ip_request_count_total'] = df.groupby('ip')['ip'].transform('count')\n\n# 2. Số lượng event_id (loại request)ユニーク mà một IP đã thực hiện\ndf['ip_unique_event_id_count'] = df.groupby('ip')['event_id_method_url'].transform('nunique')\n\n# 3. Tỷ lệ request lỗi (status_is_error=1) của một IP\n# Cần cẩn thận chia cho 0 nếu một IP không có request nào (không xảy ra nếu groupby 'ip')\n# Hoặc nếu ip_request_count_total được tính trước và có thể bằng 0 (không thể)\ndf['ip_error_rate'] = df.groupby('ip')['status_is_error'].transform('mean') # mean của 0 và 1 chính là tỷ lệ\n\n# 4. Tần suất trung bình của các event_id mà một IP truy cập\n# (event_id_method_url_freq_global)\n# Tính tần suất toàn cục của mỗi event_id trước\nevent_id_global_freq = df['event_id_method_url'].value_counts(normalize=True)\ndf['event_id_global_freq'] = df['event_id_method_url'].map(event_id_global_freq)\n\n# 5. Entropy của các event_id mà một IP đã truy cập\n# Tính toán này phức tạp hơn và thường cần một hàm tùy chỉnh với groupby().apply()\n# Đây là một ví dụ đơn giản hóa: độ hiếm trung bình của các event_id mà IP đó truy cập\ndf['ip_avg_event_id_rarity'] = df.groupby('ip')['event_id_global_freq'].transform('mean') \n# Nếu giá trị này thấp, nghĩa là IP đó thường xuyên truy cập các event_id hiếm (1/freq cao)\n\n\n# 6. Số lượng tham số query trung bình cho mỗi IP\ndf['ip_avg_query_count'] = df.groupby('ip')['url_query_count'].transform('mean')\n\n\ncols_to_show_ip_behavior = [\n    'ip', 'ip_request_count_total', 'ip_unique_event_id_count', 'ip_error_rate',\n    'event_id_global_freq', 'ip_avg_event_id_rarity', 'ip_avg_query_count'\n]\nexisting_cols_ip_b = [col for col in cols_to_show_ip_behavior if col in df.columns]\nif existing_cols_ip_b:\n    print(\"\\n--- Features Hành vi theo IP (Toàn cục) ---\")\n    print(df[existing_cols_ip_b].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Time-based feature","metadata":{}},{"cell_type":"code","source":"# --- Giả sử df đã có cột 'timestamp_dt' (đã parse sang datetime) ---\n\n# 1. Giờ trong ngày (0-23)\ndf['hour_of_day'] = df['timestamp_dt'].dt.hour\n\n# 2. Ngày trong tuần (0=Thứ Hai, 6=Chủ Nhật)\ndf['day_of_week'] = df['timestamp_dt'].dt.dayofweek # Monday=0, Sunday=6\n\n# 3. Có phải cuối tuần không? (Thứ 7 hoặc Chủ Nhật)\ndf['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n\n# 4. Phần của ngày (ví dụ: Sáng, Chiều, Tối, Đêm)\ndef get_part_of_day(hour):\n    if 5 <= hour < 12:\n        return 'morning'\n    elif 12 <= hour < 17:\n        return 'afternoon'\n    elif 17 <= hour < 21:\n        return 'evening'\n    else:\n        return 'night'\ndf['part_of_day'] = df['hour_of_day'].apply(get_part_of_day)\n\n\ncols_to_show_time = [\n    'timestamp_dt', 'hour_of_day', 'day_of_week', 'is_weekend', 'part_of_day'\n]\nexisting_cols_time = [col for col in cols_to_show_time if col in df.columns]\nif existing_cols_time:\n    print(\"\\n--- Features theo Thời gian ---\")\n    print(df[existing_cols_time].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}